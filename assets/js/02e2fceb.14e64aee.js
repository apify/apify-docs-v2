"use strict";(self.webpackChunkapify_docs_v2=self.webpackChunkapify_docs_v2||[]).push([[9151],{11114:e=>{e.exports=JSON.parse('{"pluginId":"academy","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"academy":[{"type":"link","label":"Home","href":"/academy/","docId":"index"},{"type":"category","label":"Web scraping & Automation","collapsible":false,"items":[{"type":"category","label":"Web scraping for beginners","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/academy/web-scraping-for-beginners/introduction","docId":"webscraping/web_scraping_for_beginners/introduction"},{"type":"category","label":"Basics of data collection","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Browser DevTools - I","href":"/academy/web-scraping-for-beginners/data-collection/browser-devtools","docId":"webscraping/web_scraping_for_beginners/data_collection/browser_devtools"},{"type":"link","label":"Browser DevTools - II","href":"/academy/web-scraping-for-beginners/data-collection/using-devtools","docId":"webscraping/web_scraping_for_beginners/data_collection/using_devtools"},{"type":"link","label":"Browser DevTools - III","href":"/academy/web-scraping-for-beginners/data-collection/devtools-continued","docId":"webscraping/web_scraping_for_beginners/data_collection/devtools_continued"},{"type":"link","label":"Computer preparation","href":"/academy/web-scraping-for-beginners/data-collection/computer-preparation","docId":"webscraping/web_scraping_for_beginners/data_collection/computer_preparation"},{"type":"link","label":"Project setup","href":"/academy/web-scraping-for-beginners/data-collection/project-setup","docId":"webscraping/web_scraping_for_beginners/data_collection/project_setup"},{"type":"link","label":"Node.js scraper - I","href":"/academy/web-scraping-for-beginners/data-collection/node-js-scraper","docId":"webscraping/web_scraping_for_beginners/data_collection/node_js_scraper"},{"type":"link","label":"Node.js scraper - II","href":"/academy/web-scraping-for-beginners/data-collection/node-continued","docId":"webscraping/web_scraping_for_beginners/data_collection/node_continued"},{"type":"link","label":"Saving results to CSV","href":"/academy/web-scraping-for-beginners/data-collection/save-to-csv","docId":"webscraping/web_scraping_for_beginners/data_collection/save_to_csv"}],"href":"/academy/web-scraping-for-beginners/data-collection"},{"type":"category","label":"Basics of crawling","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Recap! - Data collection","href":"/academy/web-scraping-for-beginners/crawling/recap-collection-basics","docId":"webscraping/web_scraping_for_beginners/crawling/recap_collection_basics"},{"type":"link","label":"Finding links","href":"/academy/web-scraping-for-beginners/crawling/finding-links","docId":"webscraping/web_scraping_for_beginners/crawling/finding_links"},{"type":"link","label":"Filtering links","href":"/academy/web-scraping-for-beginners/crawling/filtering-links","docId":"webscraping/web_scraping_for_beginners/crawling/filtering_links"},{"type":"link","label":"Relative URLs","href":"/academy/web-scraping-for-beginners/crawling/relative-urls","docId":"webscraping/web_scraping_for_beginners/crawling/relative_urls"},{"type":"link","label":"Your first crawl","href":"/academy/web-scraping-for-beginners/crawling/first-crawl","docId":"webscraping/web_scraping_for_beginners/crawling/first_crawl"},{"type":"link","label":"Scraping data","href":"/academy/web-scraping-for-beginners/crawling/scraping-the-data","docId":"webscraping/web_scraping_for_beginners/crawling/scraping_the_data"},{"type":"link","label":"Professional scraping","href":"/academy/web-scraping-for-beginners/crawling/pro-scraping","docId":"webscraping/web_scraping_for_beginners/crawling/pro_scraping"},{"type":"link","label":"Headless browsers","href":"/academy/web-scraping-for-beginners/crawling/headless-browser","docId":"webscraping/web_scraping_for_beginners/crawling/headless_browser"},{"type":"link","label":"Processing data","href":"/academy/web-scraping-for-beginners/crawling/processing-data","docId":"webscraping/web_scraping_for_beginners/crawling/processing_data"}],"href":"/academy/web-scraping-for-beginners/crawling"},{"type":"category","label":"Challenge","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Initializing & setting up","href":"/academy/web-scraping-for-beginners/challenge/initializing-and-setting-up","docId":"webscraping/web_scraping_for_beginners/challenge/initializing_and_setting_up"},{"type":"link","label":"Modularity","href":"/academy/web-scraping-for-beginners/challenge/modularity","docId":"webscraping/web_scraping_for_beginners/challenge/modularity"},{"type":"link","label":"Scraping Amazon","href":"/academy/web-scraping-for-beginners/challenge/scraping-amazon","docId":"webscraping/web_scraping_for_beginners/challenge/scraping_amazon"}],"href":"/academy/web-scraping-for-beginners/challenge"},{"type":"link","label":"Best practices","href":"/academy/web-scraping-for-beginners/best-practices","docId":"webscraping/web_scraping_for_beginners/best_practices"}],"href":"/academy/web-scraping-for-beginners"},{"type":"category","label":"Puppeteer & Playwright","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"I - Launching a browser","href":"/academy/puppeteer-playwright/browser","docId":"webscraping/puppeteer_playwright/browser"},{"type":"category","label":"II - Opening & controlling a page","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Interacting with a page","href":"/academy/puppeteer-playwright/page/interacting-with-a-page","docId":"webscraping/puppeteer_playwright/page/interacting_with_a_page"},{"type":"link","label":"Waiting for content & events","href":"/academy/puppeteer-playwright/page/waiting","docId":"webscraping/puppeteer_playwright/page/waiting"},{"type":"link","label":"Page methods","href":"/academy/puppeteer-playwright/page/page-methods","docId":"webscraping/puppeteer_playwright/page/page_methods"}],"href":"/academy/puppeteer-playwright/page"},{"type":"category","label":"III - Executing scripts","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Injecting scripts","href":"/academy/puppeteer-playwright/executing-scripts/injecting-code","docId":"webscraping/puppeteer_playwright/executing_scripts/injecting_code"},{"type":"link","label":"Collecting data","href":"/academy/puppeteer-playwright/executing-scripts/collecting-data","docId":"webscraping/puppeteer_playwright/executing_scripts/collecting_data"}],"href":"/academy/puppeteer-playwright/executing-scripts"},{"type":"link","label":"IV - Reading & intercepting requests","href":"/academy/puppeteer-playwright/reading-intercepting-requests","docId":"webscraping/puppeteer_playwright/reading_intercepting_requests"},{"type":"link","label":"V - Using proxies","href":"/academy/puppeteer-playwright/proxies","docId":"webscraping/puppeteer_playwright/proxies"},{"type":"link","label":"VI - Creating multiple browser contexts","href":"/academy/puppeteer-playwright/browser-contexts","docId":"webscraping/puppeteer_playwright/browser_contexts"},{"type":"category","label":"Common use cases","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Logging into a website","href":"/academy/puppeteer-playwright/common-use-cases/logging-into-a-website","docId":"webscraping/puppeteer_playwright/common_use_cases/logging_into_a_website"},{"type":"link","label":"Paginating through results","href":"/academy/puppeteer-playwright/common-use-cases/paginating-through-results","docId":"webscraping/puppeteer_playwright/common_use_cases/paginating_through_results"},{"type":"link","label":"Downloading files","href":"/academy/puppeteer-playwright/common-use-cases/downloading-files","docId":"webscraping/puppeteer_playwright/common_use_cases/downloading_files"},{"type":"link","label":"Submitting a form with a file attachment","href":"/academy/puppeteer-playwright/common-use-cases/submitting-a-form-with-a-file-attachment","docId":"webscraping/puppeteer_playwright/common_use_cases/submitting_a_form_with_a_file_attachment"},{"type":"link","label":"Scraping iFrames","href":"/academy/puppeteer-playwright/common-use-cases/scraping-iframes","docId":"webscraping/puppeteer_playwright/common_use_cases/scraping_iframes"}],"href":"/academy/puppeteer-playwright/common-use-cases"}],"href":"/academy/puppeteer-playwright"},{"type":"category","label":"API scraping","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"General API scraping","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Locating API endpoints","href":"/academy/api-scraping/general-api-scraping/locating-and-learning","docId":"webscraping/api_scraping/general_api_scraping/locating_and_learning"},{"type":"link","label":"Cookies, headers, and tokens","href":"/academy/api-scraping/general-api-scraping/cookies-headers-tokens","docId":"webscraping/api_scraping/general_api_scraping/cookies_headers_tokens"},{"type":"link","label":"Handling pagination","href":"/academy/api-scraping/general-api-scraping/handling-pagination","docId":"webscraping/api_scraping/general_api_scraping/handling_pagination"}],"href":"/academy/api-scraping/general-api-scraping"},{"type":"category","label":"GraphQL scraping","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Modifying variables","href":"/academy/api-scraping/graphql-scraping/modifying-variables","docId":"webscraping/api_scraping/graphql_scraping/modifying_variables"},{"type":"link","label":"Introspection","href":"/academy/api-scraping/graphql-scraping/introspection","docId":"webscraping/api_scraping/graphql_scraping/introspection"},{"type":"link","label":"Custom queries","href":"/academy/api-scraping/graphql-scraping/custom-queries","docId":"webscraping/api_scraping/graphql_scraping/custom_queries"}],"href":"/academy/api-scraping/graphql-scraping"}],"href":"/academy/api-scraping"},{"type":"category","label":"Switching to TypeScript","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Installation & getting started","href":"/academy/switching-to-typescript/installation","docId":"webscraping/switching_to_typescript/installation"},{"type":"link","label":"Using types - I","href":"/academy/switching-to-typescript/using-types","docId":"webscraping/switching_to_typescript/using_types"},{"type":"link","label":"Using types - II","href":"/academy/switching-to-typescript/using-types-continued","docId":"webscraping/switching_to_typescript/using_types_continued"},{"type":"link","label":"Enums","href":"/academy/switching-to-typescript/enums","docId":"webscraping/switching_to_typescript/enums"},{"type":"link","label":"Type aliases & function types","href":"/academy/switching-to-typescript/type-aliases","docId":"webscraping/switching_to_typescript/type_aliases"},{"type":"link","label":"Unknown, any, type guards & type assertions","href":"/academy/switching-to-typescript/unknown-and-type-assertions","docId":"webscraping/switching_to_typescript/unknown_and_type_assertions"},{"type":"link","label":"Watch mode & tsconfig.json","href":"/academy/switching-to-typescript/watch-mode-and-tsconfig","docId":"webscraping/switching_to_typescript/watch_mode_and_tsconfig"},{"type":"link","label":"Interfaces","href":"/academy/switching-to-typescript/interfaces","docId":"webscraping/switching_to_typescript/interfaces"},{"type":"link","label":"Mini-project","href":"/academy/switching-to-typescript/mini-project","docId":"webscraping/switching_to_typescript/mini_project"}],"href":"/academy/switching-to-typescript"},{"type":"category","label":"Advanced web scraping","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Scraping paginated sites","href":"/academy/advanced-web-scraping/scraping-paginated-sites","docId":"webscraping/advanced_web_scraping/scraping_paginated_sites"}],"href":"/academy/advanced-web-scraping"}],"collapsed":false},{"type":"category","label":"Apify Platform","collapsible":false,"items":[{"type":"link","label":"Introduction to Apify Platform","href":"/academy/apify-platform","docId":"platform/apify_platform"},{"type":"category","label":"Getting started","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Actors","href":"/academy/getting-started/actors","docId":"platform/getting_started/actors"},{"type":"link","label":"Creating actors","href":"/academy/getting-started/creating-actors","docId":"platform/getting_started/creating_actors"},{"type":"link","label":"Inputs & outputs","href":"/academy/getting-started/inputs-outputs","docId":"platform/getting_started/inputs_outputs"},{"type":"link","label":"Apify API","href":"/academy/getting-started/apify-api","docId":"platform/getting_started/apify_api"},{"type":"link","label":"Apify client","href":"/academy/getting-started/apify-client","docId":"platform/getting_started/apify_client"}],"href":"/academy/getting-started"},{"type":"category","label":"Deploying your code","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Inputs & outputs","href":"/academy/deploying-your-code/inputs-outputs","docId":"platform/deploying_your_code/inputs_outputs"},{"type":"link","label":"Input schema","href":"/academy/deploying-your-code/input-schema","docId":"platform/deploying_your_code/input_schema"},{"type":"link","label":"Output schema","href":"/academy/deploying-your-code/output-schema","docId":"platform/deploying_your_code/output_schema"},{"type":"link","label":"Dockerfile","href":"/academy/deploying-your-code/docker-file","docId":"platform/deploying_your_code/docker_file"},{"type":"link","label":"Deploying","href":"/academy/deploying-your-code/deploying","docId":"platform/deploying_your_code/deploying"}],"href":"/academy/deploying-your-code"},{"type":"category","label":"Getting the most of actors on Apify Store","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Naming your actor","href":"/academy/get-most-of-actors/naming-your-actor","docId":"platform/get_most_of_actors/naming_your_actor"},{"type":"link","label":"Actor README","href":"/academy/get-most-of-actors/actor-readme","docId":"platform/get_most_of_actors/actor_readme"},{"type":"link","label":"SEO and promotion","href":"/academy/get-most-of-actors/seo-and-promotion","docId":"platform/get_most_of_actors/seo_and_promotion"},{"type":"link","label":"Monetizing your actor","href":"/academy/get-most-of-actors/monetizing-your-actor","docId":"platform/get_most_of_actors/monetizing_your_actor"}],"href":"/academy/get-most-of-actors"},{"type":"link","label":"Running a web server on the Apify platform","href":"/academy/running-a-web-server","docId":"platform/running_a_web_server"},{"type":"category","label":"Expert scraping with Apify","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"I - Webhooks & advanced actor overview","href":"/academy/expert-scraping-with-apify/actors-webhooks","docId":"platform/expert_scraping_with_apify/actors_webhooks"},{"type":"link","label":"II - Managing source code","href":"/academy/expert-scraping-with-apify/managing-source-code","docId":"platform/expert_scraping_with_apify/managing_source_code"},{"type":"link","label":"III - Tasks & storage","href":"/academy/expert-scraping-with-apify/tasks-and-storage","docId":"platform/expert_scraping_with_apify/tasks_and_storage"},{"type":"link","label":"IV - Apify API & client","href":"/academy/expert-scraping-with-apify/apify-api-and-client","docId":"platform/expert_scraping_with_apify/apify_api_and_client"},{"type":"link","label":"V - Migrations & maintaining state","href":"/academy/expert-scraping-with-apify/migrations-maintaining-state","docId":"platform/expert_scraping_with_apify/migrations_maintaining_state"},{"type":"link","label":"VI - Bypassing anti-scraping methods","href":"/academy/expert-scraping-with-apify/bypassing-anti-scraping","docId":"platform/expert_scraping_with_apify/bypassing_anti_scraping"},{"type":"link","label":"VII - Saving useful run statistics","href":"/academy/expert-scraping-with-apify/saving-useful-stats","docId":"platform/expert_scraping_with_apify/saving_useful_stats"},{"type":"category","label":"Solutions","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"I - Integrating webhooks","href":"/academy/expert-scraping-with-apify/solutions/integrating-webhooks","docId":"platform/expert_scraping_with_apify/solutions/integrating_webhooks"},{"type":"link","label":"II - Managing source","href":"/academy/expert-scraping-with-apify/solutions/managing-source","docId":"platform/expert_scraping_with_apify/solutions/managing_source"},{"type":"link","label":"III - Using storage & creating tasks","href":"/academy/expert-scraping-with-apify/solutions/using-storage-creating-tasks","docId":"platform/expert_scraping_with_apify/solutions/using_storage_creating_tasks"},{"type":"link","label":"IV - Using the Apify API & JavaScript client","href":"/academy/expert-scraping-with-apify/solutions/using-api-and-client","docId":"platform/expert_scraping_with_apify/solutions/using_api_and_client"},{"type":"link","label":"V - Handling migrations","href":"/academy/expert-scraping-with-apify/solutions/handling-migrations","docId":"platform/expert_scraping_with_apify/solutions/handling_migrations"},{"type":"link","label":"VI - Rotating proxies/sessions","href":"/academy/expert-scraping-with-apify/solutions/rotating-proxies","docId":"platform/expert_scraping_with_apify/solutions/rotating_proxies"},{"type":"link","label":"VII - Saving run stats","href":"/academy/expert-scraping-with-apify/solutions/saving-stats","docId":"platform/expert_scraping_with_apify/solutions/saving_stats"}],"href":"/academy/expert-scraping-with-apify/solutions"}],"href":"/academy/expert-scraping-with-apify"}],"collapsed":false},{"type":"category","label":"Tutorials","collapsible":false,"items":[{"type":"link","label":"What\'s this section?","href":"/academy/tutorials","docId":"tutorials/tutorials/index"},{"type":"category","label":"Node.js tutorials","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"How to analyze and fix errors when scraping a website","href":"/academy/node-js/analyzing-pages-and-fixing-errors","docId":"tutorials/node_js/analyzing_pages_and_fixing_errors"},{"type":"link","label":"How to optimize Puppeteer by caching responses","href":"/academy/node-js/caching-responses-in-puppeteer","docId":"tutorials/node_js/caching_responses_in_puppeteer"},{"type":"link","label":"How to choose the right scraper for the job","href":"/academy/node-js/choosing-the-right-scraper","docId":"tutorials/node_js/choosing_the_right_scraper"},{"type":"link","label":"How to scrape from dynamic pages","href":"/academy/node-js/dealing-with-dynamic-pages","docId":"tutorials/node_js/dealing_with_dynamic_pages"},{"type":"link","label":"How to scrape hidden JavaScript objects in HTML","href":"/academy/node-js/js-in-html","docId":"tutorials/node_js/js_in_html"},{"type":"link","label":"How to optimize and speed up your web scraper","href":"/academy/node-js/optimizing-scrapers","docId":"tutorials/node_js/optimizing_scrapers"},{"type":"link","label":"How to scrape from sitemaps","href":"/academy/node-js/scraping-from-sitemaps","docId":"tutorials/node_js/scraping_from_sitemaps"},{"type":"link","label":"How to scrape sites with a shadow DOM","href":"/academy/node-js/scraping-shadow-doms","docId":"tutorials/node_js/scraping_shadow_doms"}],"href":"/academy/node-js"},{"type":"category","label":"Python tutorials","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"How to scrape and process data using Python","href":"/academy/python/scrape-data-python","docId":"tutorials/python/scrape_data_python"}],"href":"/academy/python"}],"collapsed":false},{"type":"category","label":"Glossary","collapsible":false,"items":[{"type":"link","label":"Why a glossary?","href":"/academy/glossary","docId":"glossary/glossary"},{"type":"category","label":"Tools","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"The Apify CLI","href":"/academy/tools/apify-cli","docId":"glossary/tools/apify_cli"},{"type":"link","label":"Insomnia","href":"/academy/tools/insomnia","docId":"glossary/tools/insomnia"},{"type":"link","label":"Postman","href":"/academy/tools/postman","docId":"glossary/tools/postman"},{"type":"link","label":"Proxyman","href":"/academy/tools/proxyman","docId":"glossary/tools/proxyman"},{"type":"link","label":"ModHeader","href":"/academy/tools/modheader","docId":"glossary/tools/modheader"},{"type":"link","label":"SwitchyOmega","href":"/academy/tools/switchyomega","docId":"glossary/tools/switchyomega"},{"type":"link","label":"EditThisCookie","href":"/academy/tools/edit-this-cookie","docId":"glossary/tools/edit_this_cookie"},{"type":"link","label":"User-Agent Switcher","href":"/academy/tools/user-agent-switcher","docId":"glossary/tools/user_agent_switcher"},{"type":"link","label":"Quick JavaScript Switcher","href":"/academy/tools/quick-javascript-switcher","docId":"glossary/tools/quick_javascript_switcher"}],"href":"/academy/tools"},{"type":"category","label":"Concepts","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"HTTP headers","href":"/academy/concepts/http-headers","docId":"glossary/concepts/http_headers"},{"type":"link","label":"HTTP cookies","href":"/academy/concepts/http-cookies","docId":"glossary/concepts/http_cookies"},{"type":"link","label":"Dynamic pages","href":"/academy/concepts/dynamic-pages","docId":"glossary/concepts/dynamic_pages"}],"href":"/academy/concepts"}],"collapsed":false}]},"docs":{"anti_scraping/index":{"id":"anti_scraping/index","title":"Anti-scraping protections","description":"Understand the various anti-scraping measures different sites use to prevent bots from accessing them, and how to appear more human to fix these issues."},"anti_scraping/mitigation/generating_fingerprints":{"id":"anti_scraping/mitigation/generating_fingerprints","title":"Generating fingerprints","description":"Learn how to use two super handy NPM libraries to easily generate fingerprints and inject them into a Playwright or Puppeteer page."},"anti_scraping/mitigation/index":{"id":"anti_scraping/mitigation/index","title":"Mitigation","description":"After learning about the various different anti-scraping techniques websites use, learn how to mitigate them with a few different techniques."},"anti_scraping/mitigation/proxies":{"id":"anti_scraping/mitigation/proxies","title":"Proxies","description":"Learn all about proxies, how they work, and how they can be leveraged in a scraper to avoid blocking and other anti-scraping tactics."},"anti_scraping/mitigation/using_proxies":{"id":"anti_scraping/mitigation/using_proxies","title":"Using proxies","description":"Learn how to use and automagically rotate proxies in your scrapers by using Crawlee, and a bit about how to easily obtain pools of proxies."},"anti_scraping/techniques/captchas":{"id":"anti_scraping/techniques/captchas","title":"Captchas","description":"Learn about the reasons a bot might be presented a captcha, the best ways to avoid captchas in the first place, and how to programmatically solve them."},"anti_scraping/techniques/fingerprinting":{"id":"anti_scraping/techniques/fingerprinting","title":"Fingerprinting","description":"Understand browser fingerprinting, an advanced technique used by browsers to track user data and even block bots from accessing them."},"anti_scraping/techniques/firewalls":{"id":"anti_scraping/techniques/firewalls","title":"Firewalls","description":"Understand what a web-application firewall is, how they work, and the various common techniques for avoiding them altogether."},"anti_scraping/techniques/geolocation":{"id":"anti_scraping/techniques/geolocation","title":"Geolocation","description":"Learn about the geolocation techniques to determine where requests are coming from, and a bit about how to avoid being blocked based on geolocation."},"anti_scraping/techniques/index":{"id":"anti_scraping/techniques/index","title":"Anti-scraping techniques","description":"Understand the various common (and obscure) anti-scraping techniques used by websites to prevent bots from accessing their content."},"anti_scraping/techniques/rate_limiting":{"id":"anti_scraping/techniques/rate_limiting","title":"Rate-limiting","description":"Learn about rate-limiting, a common tactic used by websites to avoid a large and non-human rate of requests coming from a single IP address."},"glossary/concepts/dynamic_pages":{"id":"glossary/concepts/dynamic_pages","title":"Dynamic pages","description":"Understand what makes a page dynamic, and how a page being dynamic might change your approach when writing a scraper for it.","sidebar":"academy"},"glossary/concepts/http_cookies":{"id":"glossary/concepts/http_cookies","title":"HTTP cookies","description":"Learn a bit about what cookies are, and how they are utilized in scrapers to appear logged-in, view specific data, or even avoid blocking.","sidebar":"academy"},"glossary/concepts/http_headers":{"id":"glossary/concepts/http_headers","title":"HTTP headers","description":"Understand what HTTP headers are, what they\'re used for, and three of the biggest differences between HTTP/1.1 and HTTP/2 headers.","sidebar":"academy"},"glossary/concepts/index":{"id":"glossary/concepts/index","title":"Concepts","description":"Learn about some common yet tricky concepts and terms that are used frequently within the academy, as well as in the world of scraper development.","sidebar":"academy"},"glossary/glossary":{"id":"glossary/glossary","title":"Why a glossary?","description":"Browse important web scraping concepts, tools and topics in succinct articles explaining common web development terms in a web scraping and automation context.","sidebar":"academy"},"glossary/tools/apify_cli":{"id":"glossary/tools/apify_cli","title":"The Apify CLI","description":"Learn about, install, and log into the Apify CLI - your best friend for interacting with the Apify platform via your terminal.","sidebar":"academy"},"glossary/tools/edit_this_cookie":{"id":"glossary/tools/edit_this_cookie","title":"EditThisCookie","description":"Learn how to add, delete, and modify different cookies in your browser for testing purposes using the EditThisCookie chrome extension.","sidebar":"academy"},"glossary/tools/index":{"id":"glossary/tools/index","title":"Tools","description":"Discover a variety of tools that can be used to enhance the scraper development process, or even unlock doors to new scraping possibilities.","sidebar":"academy"},"glossary/tools/insomnia":{"id":"glossary/tools/insomnia","title":"Insomnia","description":"Learn about Insomnia, a simple yet super valuable tool for testing requests and proxies when building scalable web scrapers.","sidebar":"academy"},"glossary/tools/modheader":{"id":"glossary/tools/modheader","title":"ModHeader","description":"Discover a super useful Chrome extension called ModHeader, which allows you to modify your browser\'s HTTP request headers.","sidebar":"academy"},"glossary/tools/postman":{"id":"glossary/tools/postman","title":"Postman","description":"Learn about Postman, a simple yet super valuable tool for testing requests and proxies when building scalable web scrapers.","sidebar":"academy"},"glossary/tools/proxyman":{"id":"glossary/tools/proxyman","title":"Proxyman","description":"Learn about Proxyman, a tool for viewing all network requests that are coming through your system. Filter by response type, by a keyword, or by application.","sidebar":"academy"},"glossary/tools/quick_javascript_switcher":{"id":"glossary/tools/quick_javascript_switcher","title":"Quick JavaScript Switcher","description":"Discover a super simple tool for disabling JavaScript on a certain page to determine how it should be scraped. Great for detecting SPAs.","sidebar":"academy"},"glossary/tools/switchyomega":{"id":"glossary/tools/switchyomega","title":"SwitchyOmega","description":"Discover SwitchyOmega, a Chrome extension to manage and switch between proxies, which is extremely useful when testing proxies for a scraper.","sidebar":"academy"},"glossary/tools/user_agent_switcher":{"id":"glossary/tools/user_agent_switcher","title":"User-Agent Switcher","description":"Learn how to easily switch your User-Agent header to different values in order to monitor how a certain site responds to the changes.","sidebar":"academy"},"index":{"id":"index","title":"Home","description":"Learn everything about web scraping and automation with our free courses that will turn you into an expert scraper developer.","sidebar":"academy"},"platform/apify_platform":{"id":"platform/apify_platform","title":"Introduction to Apify Platform","description":"Learn all about the Apify platform, all of the tools it offers, and how it can improve your overall development experience.","sidebar":"academy"},"platform/deploying_your_code/deploying":{"id":"platform/deploying_your_code/deploying","title":"Deploying","description":"Push local code to the platform, or create a new actor on the console and integrate it with a Git repo to optionally automatically rebuild any new changes.","sidebar":"academy"},"platform/deploying_your_code/docker_file":{"id":"platform/deploying_your_code/docker_file","title":"Dockerfile","description":"Understand how to write a Dockerfile (Docker image blueprint) for your project so that it can be run within a Docker container on the Apify platform.","sidebar":"academy"},"platform/deploying_your_code/index":{"id":"platform/deploying_your_code/index","title":"Deploying your code","description":"In this course learn how to take an existing project of yours and deploy it to the Apify platform as an actor in just a few minutes!","sidebar":"academy"},"platform/deploying_your_code/input_schema":{"id":"platform/deploying_your_code/input_schema","title":"Input schema","description":"Learn how to generate a user interface on the platform for your actor\'s input with a single file - the INPUT_SCHEMA.json file.","sidebar":"academy"},"platform/deploying_your_code/inputs_outputs":{"id":"platform/deploying_your_code/inputs_outputs","title":"Inputs & outputs","description":"Learn to accept input into your actor, do something with it, then return output. Actors can be written in any language, so this concept is language agnostic.","sidebar":"academy"},"platform/deploying_your_code/output_schema":{"id":"platform/deploying_your_code/output_schema","title":"Output schema","description":"Learn how to generate an appealing Overview table interface to preview your actor results in real time on the Apify Platform.","sidebar":"academy"},"platform/expert_scraping_with_apify/actors_webhooks":{"id":"platform/expert_scraping_with_apify/actors_webhooks","title":"I - Webhooks & advanced actor overview","description":"Learn more advanced details about actors, how they work, and the default configurations they can take. Also learn how to integrate your actor with webhooks.","sidebar":"academy"},"platform/expert_scraping_with_apify/apify_api_and_client":{"id":"platform/expert_scraping_with_apify/apify_api_and_client","title":"IV - Apify API & client","description":"Gain an in-depth understanding of the two main ways of programmatically interacting with the Apify platform - through the API, and through a client.","sidebar":"academy"},"platform/expert_scraping_with_apify/bypassing_anti_scraping":{"id":"platform/expert_scraping_with_apify/bypassing_anti_scraping","title":"VI - Bypassing anti-scraping methods","description":"Learn about bypassing anti-scraping methods using proxies and proxy/session rotation together with Crawlee and the Apify SDK.","sidebar":"academy"},"platform/expert_scraping_with_apify/index":{"id":"platform/expert_scraping_with_apify/index","title":"Expert scraping with Apify","description":"After learning the basics of actors and Apify, learn to develop pro-level scrapers on the Apify platform with this advanced course.","sidebar":"academy"},"platform/expert_scraping_with_apify/managing_source_code":{"id":"platform/expert_scraping_with_apify/managing_source_code","title":"II - Managing source code","description":"Learn how to manage your actor\'s source code more efficiently by integrating it with a Github repository. This is the standard on the Apify platform.","sidebar":"academy"},"platform/expert_scraping_with_apify/migrations_maintaining_state":{"id":"platform/expert_scraping_with_apify/migrations_maintaining_state","title":"V - Migrations & maintaining state","description":"Learn about what actor migrations are and how to handle them properly so that state is not lost and it can safely be resurrected.","sidebar":"academy"},"platform/expert_scraping_with_apify/saving_useful_stats":{"id":"platform/expert_scraping_with_apify/saving_useful_stats","title":"VII - Saving useful run statistics","description":"Understand how to save statistics about an actor\'s run, what types of statistics you can save, and why you might want to save them for a large-scale scraper.","sidebar":"academy"},"platform/expert_scraping_with_apify/solutions/handling_migrations":{"id":"platform/expert_scraping_with_apify/solutions/handling_migrations","title":"V - Handling migrations","description":"Get real-world experience of maintaining a stateful object stored in memory, which will be persisted through migrations and even graceful aborts.","sidebar":"academy"},"platform/expert_scraping_with_apify/solutions/index":{"id":"platform/expert_scraping_with_apify/solutions/index","title":"Solutions","description":"View all of the solutions for all of the activities and tasks of this course. Please try to complete each task on your own before reading the solution!","sidebar":"academy"},"platform/expert_scraping_with_apify/solutions/integrating_webhooks":{"id":"platform/expert_scraping_with_apify/solutions/integrating_webhooks","title":"I - Integrating webhooks","description":"Learn how to integrate webhooks into your actors. Webhooks are a super powerful tool, and can be used to do almost anything!","sidebar":"academy"},"platform/expert_scraping_with_apify/solutions/managing_source":{"id":"platform/expert_scraping_with_apify/solutions/managing_source","title":"II - Managing source","description":"View in-depth answers for all three of the quiz questions that were provided in the corresponding lesson about managing source code.","sidebar":"academy"},"platform/expert_scraping_with_apify/solutions/rotating_proxies":{"id":"platform/expert_scraping_with_apify/solutions/rotating_proxies","title":"VI - Rotating proxies/sessions","description":"Learn first hand how to rotate proxies and sessions in order to avoid the majority of the most common anti-scraping protections.","sidebar":"academy"},"platform/expert_scraping_with_apify/solutions/saving_stats":{"id":"platform/expert_scraping_with_apify/solutions/saving_stats","title":"VII - Saving run stats","description":"Implement the saving of general statistics about an actor\'s run, as well as adding request-specific statistics to dataset items.","sidebar":"academy"},"platform/expert_scraping_with_apify/solutions/using_api_and_client":{"id":"platform/expert_scraping_with_apify/solutions/using_api_and_client","title":"IV - Using the Apify API & JavaScript client","description":"Learn how to interact with the Apify API directly through the well-documented RESTful routes, or by using the proprietary Apify JavaScript client.","sidebar":"academy"},"platform/expert_scraping_with_apify/solutions/using_storage_creating_tasks":{"id":"platform/expert_scraping_with_apify/solutions/using_storage_creating_tasks","title":"III - Using storage & creating tasks","description":"Follow along with step-by-step instructions on how to complete the task outlined in the previous lesson. Use different storage types, and create a task.","sidebar":"academy"},"platform/expert_scraping_with_apify/tasks_and_storage":{"id":"platform/expert_scraping_with_apify/tasks_and_storage","title":"III - Tasks & storage","description":"Understand how to save the configurations for actors with actor tasks. Also, learn about storage and the different types Apify offers.","sidebar":"academy"},"platform/get_most_of_actors/actor_readme":{"id":"platform/get_most_of_actors/actor_readme","title":"Actor README","description":"Learn how to write a comprehensive README to help users better navigate, understand and run public actors in Apify Store.","sidebar":"academy"},"platform/get_most_of_actors/index":{"id":"platform/get_most_of_actors/index","title":"Getting the most of actors on Apify Store","description":"Learn how to optimize your public actors on Apify Store and monetize them by renting your actor to other platform users.","sidebar":"academy"},"platform/get_most_of_actors/monetizing_your_actor":{"id":"platform/get_most_of_actors/monetizing_your_actor","title":"Monetizing your actor","description":"Learn how you can monetize your web scraping and automation projects by publishing and renting actors to users in Apify Store.","sidebar":"academy"},"platform/get_most_of_actors/naming_your_actor":{"id":"platform/get_most_of_actors/naming_your_actor","title":"Naming your actor","description":"Apify\'s standards for actor naming. Learn how to choose the right name for scraping and non-scraping actors and how to optimize your actor for search engines.","sidebar":"academy"},"platform/get_most_of_actors/seo_and_promotion":{"id":"platform/get_most_of_actors/seo_and_promotion","title":"SEO and promotion","description":"Optimize your actors to get more relevant visits from search engines like Google. Set search engine-friendly parameters and share your actor with the world.","sidebar":"academy"},"platform/getting_started/actors":{"id":"platform/getting_started/actors","title":"Actors","description":"What is an actor? How do we create them? Learn the basics of what actors are, how they work, and try out an actor yourself right on the Apify platform!","sidebar":"academy"},"platform/getting_started/apify_api":{"id":"platform/getting_started/apify_api","title":"Apify API","description":"Learn how to use the Apify API to programmatically call your actors, retrieve data stored on the platform, view actor logs, and more!","sidebar":"academy"},"platform/getting_started/apify_client":{"id":"platform/getting_started/apify_client","title":"Apify client","description":"Interact with the Apify API in your code by using the apify-client package, which is available for both JavaScript and Python.","sidebar":"academy"},"platform/getting_started/creating_actors":{"id":"platform/getting_started/creating_actors","title":"Creating actors","description":"Build and run your very first actor right on the Apify platform from a template. This lesson provides a hands-on experience with building and running an actor.","sidebar":"academy"},"platform/getting_started/index":{"id":"platform/getting_started/index","title":"Getting started","description":"Get started with the Apify platform by creating an account and learning about the Apify Console, which is where all Apify actors are born!","sidebar":"academy"},"platform/getting_started/inputs_outputs":{"id":"platform/getting_started/inputs_outputs","title":"Inputs & outputs","description":"Create an actor from scratch which takes an input, processes that input, then outputs a result that can be used elsewhere.","sidebar":"academy"},"platform/running_a_web_server":{"id":"platform/running_a_web_server","title":"Running a web server on the Apify platform","description":"A web server running in an actor can act as a communication channel with the outside world. Learn how to easily set one up with Node.js.","sidebar":"academy"},"tutorials/node_js/analyzing_pages_and_fixing_errors":{"id":"tutorials/node_js/analyzing_pages_and_fixing_errors","title":"How to analyze and fix errors when scraping a website","description":"Learn how to deal with random crashes in your web-scraping and automation jobs. Find out the essentials of debugging and fixing problems in your crawlers.","sidebar":"academy"},"tutorials/node_js/caching_responses_in_puppeteer":{"id":"tutorials/node_js/caching_responses_in_puppeteer","title":"How to optimize Puppeteer by caching responses","description":"Learn why it is important for performance to cache responses in memory when intercepting requests in Puppeteer and how to implement it in your code.","sidebar":"academy"},"tutorials/node_js/choosing_the_right_scraper":{"id":"tutorials/node_js/choosing_the_right_scraper","title":"How to choose the right scraper for the job","description":"Learn basic web scraping concepts to help you analyze a website and choose the best scraper for your particular use case.","sidebar":"academy"},"tutorials/node_js/dealing_with_dynamic_pages":{"id":"tutorials/node_js/dealing_with_dynamic_pages","title":"How to scrape from dynamic pages","description":"Learn about dynamic pages and dynamic content. How can we find out if a page is dynamic? How do we programmatically scrape dynamic content?","sidebar":"academy"},"tutorials/node_js/index":{"id":"tutorials/node_js/index","title":"Node.js tutorials","description":"A collection of various Node.js tutorials on scraping sitemaps, optimizing your scrapers, using popular Node.js web scraping libraries, and more.","sidebar":"academy"},"tutorials/node_js/js_in_html":{"id":"tutorials/node_js/js_in_html","title":"How to scrape hidden JavaScript objects in HTML","description":"Learn about \\"hidden\\" data found within the JavaScript of certain pages, which can increase the scraper reliability and improve your development experience.","sidebar":"academy"},"tutorials/node_js/optimizing_scrapers":{"id":"tutorials/node_js/optimizing_scrapers","title":"How to optimize and speed up your web scraper","description":"We all want our scrapers to run as cost-effective as possible. Learn how to think about performance in the context of web scraping and automation.","sidebar":"academy"},"tutorials/node_js/scraping_from_sitemaps":{"id":"tutorials/node_js/scraping_from_sitemaps","title":"How to scrape from sitemaps","description":"The sitemap.xml file is a jackpot for every web scraper developer. Take advantage of this and learn an easier way to extract data from websites using Crawlee.","sidebar":"academy"},"tutorials/node_js/scraping_shadow_doms":{"id":"tutorials/node_js/scraping_shadow_doms","title":"How to scrape sites with a shadow DOM","description":"The shadow DOM enables the isolation of web components, but causes problems for those building web scrapers. Here\'s an easy workaround.","sidebar":"academy"},"tutorials/python/index":{"id":"tutorials/python/index","title":"Python tutorials","description":"A collection of various Python tutorials to aid you in your journey to becoming a master web scraping and automation developer.","sidebar":"academy"},"tutorials/python/scrape_data_python":{"id":"tutorials/python/scrape_data_python","title":"How to scrape and process data using Python","description":"Learn how to create a Python actor and use Python libraries to scrape, process and visualize data extracted from the web.","sidebar":"academy"},"tutorials/tutorials/index":{"id":"tutorials/tutorials/index","title":"What\'s this section?","description":"Learn about various different specific topics related to web-scraping and web-automation with the Apify Academy tutorial lessons!","sidebar":"academy"},"webscraping/advanced_web_scraping/index":{"id":"webscraping/advanced_web_scraping/index","title":"Advanced web scraping","description":"Take your scrapers to the next level by learning various advanced concepts and techniques that will help you build highly scalable and reliable crawlers.","sidebar":"academy"},"webscraping/advanced_web_scraping/scraping_paginated_sites":{"id":"webscraping/advanced_web_scraping/scraping_paginated_sites","title":"Scraping paginated sites","description":"Learn how to extract all of a website\'s listings even if they limit the number of results pages. See code examples for setting up your scraper.","sidebar":"academy"},"webscraping/api_scraping/general_api_scraping/cookies_headers_tokens":{"id":"webscraping/api_scraping/general_api_scraping/cookies_headers_tokens","title":"Cookies, headers, and tokens","description":"Learn about how some APIs require certain cookies, headers, and/or tokens to be present in a request in order for data to be received.","sidebar":"academy"},"webscraping/api_scraping/general_api_scraping/handling_pagination":{"id":"webscraping/api_scraping/general_api_scraping/handling_pagination","title":"Handling pagination","description":"Learn about the three most popular API pagination techniques and how to handle each of them when scraping an API with pagination.","sidebar":"academy"},"webscraping/api_scraping/general_api_scraping/index":{"id":"webscraping/api_scraping/general_api_scraping/index","title":"General API scraping","description":"Learn the benefits and drawbacks of API scraping, how to locate an API, how to utilize its features, and how to work around common roadblocks.","sidebar":"academy"},"webscraping/api_scraping/general_api_scraping/locating_and_learning":{"id":"webscraping/api_scraping/general_api_scraping/locating_and_learning","title":"Locating API endpoints","description":"Learn how to effectively locate a website\'s API endpoints, and learn how to use them to get the data you want faster and more reliably.","sidebar":"academy"},"webscraping/api_scraping/graphql_scraping/custom_queries":{"id":"webscraping/api_scraping/graphql_scraping/custom_queries","title":"Custom queries","description":"Learn how to write custom GraphQL queries, how to pass input values into GraphQL requests as variables, and how to retrieve and output the data from a scraper.","sidebar":"academy"},"webscraping/api_scraping/graphql_scraping/index":{"id":"webscraping/api_scraping/graphql_scraping/index","title":"GraphQL scraping","description":"Dig into the topic of scraping APIs which use the latest and greatest API technology - GraphQL. GraphQL APIs are very different from regular REST APIs.","sidebar":"academy"},"webscraping/api_scraping/graphql_scraping/introspection":{"id":"webscraping/api_scraping/graphql_scraping/introspection","title":"Introspection","description":"Understand what introspection is, and how it can help you understand a GraphQL API to take advantage the features it has to offer before writing any code.","sidebar":"academy"},"webscraping/api_scraping/graphql_scraping/modifying_variables":{"id":"webscraping/api_scraping/graphql_scraping/modifying_variables","title":"Modifying variables","description":"Learn how to modify the variables of a JSON format GraphQL query to use the API without needing to write any GraphQL language or create custom queries.","sidebar":"academy"},"webscraping/api_scraping/index":{"id":"webscraping/api_scraping/index","title":"API scraping","description":"Learn all about how the professionals scrape various types of APIs with various configurations, parameters, and requirements.","sidebar":"academy"},"webscraping/puppeteer_playwright/browser":{"id":"webscraping/puppeteer_playwright/browser","title":"I - Launching a browser","description":"Understand what the Browser object is in Puppeteer/Playwright, how to create one, and a bit about how to interact with one.","sidebar":"academy"},"webscraping/puppeteer_playwright/browser_contexts":{"id":"webscraping/puppeteer_playwright/browser_contexts","title":"VI - Creating multiple browser contexts","description":"Learn what a browser context is, how to create one, how to emulate devices, and how to use browser contexts to automate multiple sessions at one time.","sidebar":"academy"},"webscraping/puppeteer_playwright/common_use_cases/downloading_files":{"id":"webscraping/puppeteer_playwright/common_use_cases/downloading_files","title":"Downloading files","description":"Learn how to automatically download and save files to the disk using two of the most popular web automation libraries, Puppeteer and Playwright.","sidebar":"academy"},"webscraping/puppeteer_playwright/common_use_cases/index":{"id":"webscraping/puppeteer_playwright/common_use_cases/index","title":"Common use cases","description":"Learn about some of the most common uses cases of Playwright and Puppeteer, and how to handle these use cases when you run into them.","sidebar":"academy"},"webscraping/puppeteer_playwright/common_use_cases/logging_into_a_website":{"id":"webscraping/puppeteer_playwright/common_use_cases/logging_into_a_website","title":"Logging into a website","description":"Understand the \\"login flow\\" - logging into a website, then maintaining a logged in status within different browser contexts for an efficient automation process.","sidebar":"academy"},"webscraping/puppeteer_playwright/common_use_cases/paginating_through_results":{"id":"webscraping/puppeteer_playwright/common_use_cases/paginating_through_results","title":"Paginating through results","description":"Learn how to paginate through results on websites that use either page number-based pagination or dynamic lazy-loading pagination.","sidebar":"academy"},"webscraping/puppeteer_playwright/common_use_cases/scraping_iframes":{"id":"webscraping/puppeteer_playwright/common_use_cases/scraping_iframes","title":"Scraping iFrames","description":"Extracting data from iFrames can be frustrating. In this tutorial, we will learn how to scrape information from iFrames using Puppeteer or Playwright.","sidebar":"academy"},"webscraping/puppeteer_playwright/common_use_cases/submitting_a_form_with_a_file_attachment":{"id":"webscraping/puppeteer_playwright/common_use_cases/submitting_a_form_with_a_file_attachment","title":"Submitting a form with a file attachment","description":"Understand how to download a file, attach it to a form using a headless browser in Playwright or Puppeteer, then submit the form.","sidebar":"academy"},"webscraping/puppeteer_playwright/executing_scripts/collecting_data":{"id":"webscraping/puppeteer_playwright/executing_scripts/collecting_data","title":"Collecting data","description":"Learn how to collect data from a page with evaluate functions, then how to safely collect it by using a second library called Cheerio.","sidebar":"academy"},"webscraping/puppeteer_playwright/executing_scripts/index":{"id":"webscraping/puppeteer_playwright/executing_scripts/index","title":"III - Executing scripts","description":"Understand the two different contexts which your code can be run in, and how to run custom scripts in the context of the browser.","sidebar":"academy"},"webscraping/puppeteer_playwright/executing_scripts/injecting_code":{"id":"webscraping/puppeteer_playwright/executing_scripts/injecting_code","title":"Injecting scripts","description":"Learn how to inject scripts prior to a page\'s load (pre-injecting), as well as how to expose functions to be run at a later time on the page.","sidebar":"academy"},"webscraping/puppeteer_playwright/index":{"id":"webscraping/puppeteer_playwright/index","title":"Puppeteer & Playwright","description":"Learn in-depth how to use two of the most popular Node.js libraries for controlling a headless browser - Puppeteer and Playwright.","sidebar":"academy"},"webscraping/puppeteer_playwright/page/index":{"id":"webscraping/puppeteer_playwright/page/index","title":"II - Opening & controlling a page","description":"Learn how to create and open a Page with a Browser, and how to use it to visit and programmatically interact with a website.","sidebar":"academy"},"webscraping/puppeteer_playwright/page/interacting_with_a_page":{"id":"webscraping/puppeteer_playwright/page/interacting_with_a_page","title":"Interacting with a page","description":"Learn how to programmatically do actions on a page such as clicking, typing, and pressing keys. Also, discover a common roadblock that comes up when automating.","sidebar":"academy"},"webscraping/puppeteer_playwright/page/page_methods":{"id":"webscraping/puppeteer_playwright/page/page_methods","title":"Page methods","description":"Understand that the Page object has many different methods to offer, and learn how to use two of them to capture a page\'s title and take a screenshot.","sidebar":"academy"},"webscraping/puppeteer_playwright/page/waiting":{"id":"webscraping/puppeteer_playwright/page/waiting","title":"Waiting for content & events","description":"Learn the importance of waiting for content and events before running interaction/collection code, as well as the best practices for doing so.","sidebar":"academy"},"webscraping/puppeteer_playwright/proxies":{"id":"webscraping/puppeteer_playwright/proxies","title":"V - Using proxies","description":"Understand how to use proxies in your Puppeteer and Playwright requests, as well as a couple of the most common use cases for proxies.","sidebar":"academy"},"webscraping/puppeteer_playwright/reading_intercepting_requests":{"id":"webscraping/puppeteer_playwright/reading_intercepting_requests","title":"IV - Reading & intercepting requests","description":"You can use DevTools, but did you know that you can do all the same stuff (plus more) programmatically? Read and intercept requests in Puppeteer/Playwright.","sidebar":"academy"},"webscraping/switching_to_typescript/enums":{"id":"webscraping/switching_to_typescript/enums","title":"Enums","description":"Learn how to easily define, use, and manage constant values using a cool feature called \\"enums\\" that TypeScript brings to the table.","sidebar":"academy"},"webscraping/switching_to_typescript/index":{"id":"webscraping/switching_to_typescript/index","title":"Switching to TypeScript","description":"In this course, learn what TypeScript is, why you should use it instead of vanilla JavaScript, and how to start using it in your own projects.","sidebar":"academy"},"webscraping/switching_to_typescript/installation":{"id":"webscraping/switching_to_typescript/installation","title":"Installation & getting started","description":"Install TypeScript and the TS compiler on your machine, then write your very first lines of TypeScript code by fixing a logical bug in a vanilla JS snippet.","sidebar":"academy"},"webscraping/switching_to_typescript/interfaces":{"id":"webscraping/switching_to_typescript/interfaces","title":"Interfaces","description":"Understand how to declare object types with the \\"interface\\" keyword, and the subtle difference interfaces have with regular type aliases.","sidebar":"academy"},"webscraping/switching_to_typescript/mini_project":{"id":"webscraping/switching_to_typescript/mini_project","title":"Mini-project","description":"Build an entire project in TypeScript using concepts learned in this course. Also, learn about two more advanced TypeScript features.","sidebar":"academy"},"webscraping/switching_to_typescript/type_aliases":{"id":"webscraping/switching_to_typescript/type_aliases","title":"Type aliases & function types","description":"Create your own custom types using the \\"type\\" keyword, understand the \\"void\\" type, and learn how to write custom function types.","sidebar":"academy"},"webscraping/switching_to_typescript/unknown_and_type_assertions":{"id":"webscraping/switching_to_typescript/unknown_and_type_assertions","title":"Unknown, any, type guards & type assertions","description":"Understand the \\"unknown\\" and \\"any\\" types, as well as using type guards to make your code safer and type assertions to avoid common TypeScript compiler errors.","sidebar":"academy"},"webscraping/switching_to_typescript/using_types":{"id":"webscraping/switching_to_typescript/using_types","title":"Using types - I","description":"Dip your toes into using types with TypeScript by learning about the core types offered by the language, and how to define variables and functions with them.","sidebar":"academy"},"webscraping/switching_to_typescript/using_types_continued":{"id":"webscraping/switching_to_typescript/using_types_continued","title":"Using types - II","description":"Continue learning about the core types in TypeScript. In this second part lesson, learn how to use and define object types, array types, and tuples.","sidebar":"academy"},"webscraping/switching_to_typescript/watch_mode_and_tsconfig":{"id":"webscraping/switching_to_typescript/watch_mode_and_tsconfig","title":"Watch mode & tsconfig.json","description":"Learn how to fine-tune TypeScript for an entire project\'s needs and efficiently compile numerous TS files at a single time (automagically).","sidebar":"academy"},"webscraping/web_scraping_for_beginners/best_practices":{"id":"webscraping/web_scraping_for_beginners/best_practices","title":"Best practices","description":"Understand the standards and best practices that we here at Apify abide by to write readable, scalable, and maintainable code.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/challenge/index":{"id":"webscraping/web_scraping_for_beginners/challenge/index","title":"Challenge","description":"Test your knowledge acquired in the previous sections of this course by building an Amazon scraper using Crawlee\'s CheerioCrawler!","sidebar":"academy"},"webscraping/web_scraping_for_beginners/challenge/initializing_and_setting_up":{"id":"webscraping/web_scraping_for_beginners/challenge/initializing_and_setting_up","title":"Initializing & setting up","description":"When you collect links from a web page, you often end up with a lot of irrelevant URLs. Learn how to filter the links to only keep the ones you need.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/challenge/modularity":{"id":"webscraping/web_scraping_for_beginners/challenge/modularity","title":"Modularity","description":"Before you build your first web scraper with Crawlee, it is important to understand the concept of modularity in programming.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/challenge/scraping_amazon":{"id":"webscraping/web_scraping_for_beginners/challenge/scraping_amazon","title":"Scraping Amazon","description":"Before you build your first web scraper with Crawlee, it is important to understand the concept of modularity in programming.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/crawling/filtering_links":{"id":"webscraping/web_scraping_for_beginners/crawling/filtering_links","title":"Filtering links","description":"When you collect links from a web page, you often end up with a lot of irrelevant URLs. Learn how to filter the links to only keep the ones you need.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/crawling/finding_links":{"id":"webscraping/web_scraping_for_beginners/crawling/finding_links","title":"Finding links","description":"Learn what a link looks like in HTML and how to find and collect their URLs when web scraping using both DevTools and Node.js.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/crawling/first_crawl":{"id":"webscraping/web_scraping_for_beginners/crawling/first_crawl","title":"Your first crawl","description":"Learn how to crawl the web using Node.js, Cheerio and an HTTP client. Collect URLs from pages and use them to visit more websites.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/crawling/headless_browser":{"id":"webscraping/web_scraping_for_beginners/crawling/headless_browser","title":"Headless browsers","description":"Learn how to scrape the web with a headless browser using only a few lines of code. Chrome, Firefox, Safari, Edge - all are supported.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/crawling/index":{"id":"webscraping/web_scraping_for_beginners/crawling/index","title":"Basics of crawling","description":"Learn how to crawl the web with your scraper. How to extract links and URLs from web pages and how to manage the collected links to crawl the web.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/crawling/pro_scraping":{"id":"webscraping/web_scraping_for_beginners/crawling/pro_scraping","title":"Professional scraping","description":"Learn how to build scrapers quicker and get better and more robust results by using Crawlee, an open-source library for scraping in Node.js.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/crawling/processing_data":{"id":"webscraping/web_scraping_for_beginners/crawling/processing_data","title":"Processing data","description":"Learn how to process the data you scraped using the Crawlee library and how to convert JSON files to Excel using the Apify API.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/crawling/recap_collection_basics":{"id":"webscraping/web_scraping_for_beginners/crawling/recap_collection_basics","title":"Recap! - Data collection","description":"Review our e-commerce website scraper and refresh our memory about its code and the programming techniques we used to collect and save the data.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/crawling/relative_urls":{"id":"webscraping/web_scraping_for_beginners/crawling/relative_urls","title":"Relative URLs","description":"Learn about absolute and relative URLs used on web pages and how to work with them when parsing HTML with Cheerio in your scraper.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/crawling/scraping_the_data":{"id":"webscraping/web_scraping_for_beginners/crawling/scraping_the_data","title":"Scraping data","description":"Learn how to add data collection logic to your crawler, which will allow you to extract data from all the websites you crawled.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/data_collection/browser_devtools":{"id":"webscraping/web_scraping_for_beginners/data_collection/browser_devtools","title":"Browser DevTools - I","description":"Learn about browser DevTools, a valuable tool in the world of web scraping , and how you can use them to collect data from a website.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/data_collection/computer_preparation":{"id":"webscraping/web_scraping_for_beginners/data_collection/computer_preparation","title":"Computer preparation","description":"Set up your computer to be able to code scrapers with Node.js and JavaScript. Download Node.js and NPM and run a Hello World script.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/data_collection/devtools_continued":{"id":"webscraping/web_scraping_for_beginners/data_collection/devtools_continued","title":"Browser DevTools - III","description":"Continue learning how to collect data from a website using browser DevTools, CSS selectors, and JavaScript via the DevTools console.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/data_collection/index":{"id":"webscraping/web_scraping_for_beginners/data_collection/index","title":"Basics of data collection","description":"Learn about HTML, CSS, and JavaScript, the basic building blocks of a website, and how to use them in web scraping and data collection.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/data_collection/node_continued":{"id":"webscraping/web_scraping_for_beginners/data_collection/node_continued","title":"Node.js scraper - II","description":"Continue learning how to create a web scraper with Node.js and Cheerio. Learn how to parse HTML and print the results of the data your scraper has collected.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/data_collection/node_js_scraper":{"id":"webscraping/web_scraping_for_beginners/data_collection/node_js_scraper","title":"Node.js scraper - I","description":"Learn how to use JavaScript and Node.js to create a web scraper, plus take advantage of the cheerio and got-scraping libraries to make your job easier.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/data_collection/project_setup":{"id":"webscraping/web_scraping_for_beginners/data_collection/project_setup","title":"Project setup","description":"Create a new project with NPM and Node.js. Install necessary libraries, and test that everything works before starting the next modules.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/data_collection/save_to_csv":{"id":"webscraping/web_scraping_for_beginners/data_collection/save_to_csv","title":"Saving results to CSV","description":"Learn how to save the results of your scraper\'s collected data to a CSV file that can be opened in Excel, Google Sheets, or any other spreadsheets program.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/data_collection/using_devtools":{"id":"webscraping/web_scraping_for_beginners/data_collection/using_devtools","title":"Browser DevTools - II","description":"Learn how to use browser DevTools, CSS selectors, and JavaScript via the DevTools console to collect data from a website.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/index":{"id":"webscraping/web_scraping_for_beginners/index","title":"Web scraping for beginners","description":"Learn how to develop web scrapers with this comprehensive and practical course. Go from beginner to expert, all in one place.","sidebar":"academy"},"webscraping/web_scraping_for_beginners/introduction":{"id":"webscraping/web_scraping_for_beginners/introduction","title":"Introduction","description":"Start learning about web scraping, web crawling, data collection, and popular tools to start developing your own scraper.","sidebar":"academy"}}}')}}]);